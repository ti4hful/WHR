whr.ipynb

pip install mysql-connector-python

import mysql.connector

def connectToDatabase(host,user,password,database):
    connector = mysql.connector.connect(
        host=host,
        user=user,
        password=password,
        database=database
    )
    return connector

connection = connectToDatabase("localhost","root","root","whr")

cursor = connection.cursor()

pip install sqlalchemy

import pandas as pd
from sqlalchemy import create_engine


engine = create_engine('mysql+mysqlconnector://root:root@localhost:3306/whr')

cursor = connection.cursor()

data_2015 = pd.read_csv(r'C:\FINAL\WHR\dataset\2015.csv')
data_2016 = pd.read_csv(r'C:\FINAL\WHR\dataset\2016.csv')
data_2017 = pd.read_csv(r'C:\FINAL\WHR\dataset\2017.csv')
data_2018 = pd.read_csv(r'C:\FINAL\WHR\dataset\2018.csv')
data_2019 = pd.read_csv(r'C:\FINAL\WHR\dataset\2019.csv')
data_2020 = pd.read_csv(r'C:\FINAL\WHR\dataset\2020.csv')
data_2021 = pd.read_csv(r'C:\FINAL\WHR\dataset\2021.csv')
data_2022 = pd.read_csv(r'C:\FINAL\WHR\dataset\2022.csv')

data_2015.to_sql('happiness_2015', engine, index=False, if_exists='replace')
data_2016.to_sql('happiness_2016', engine, index=False, if_exists='replace')
data_2017.to_sql('happiness_2017', engine, index=False, if_exists='replace')
data_2018.to_sql('happiness_2018', engine, index=False, if_exists='replace')
data_2019.to_sql('happiness_2019', engine, index=False, if_exists='replace')
data_2020.to_sql('happiness_2020', engine, index=False, if_exists='replace')
data_2021.to_sql('happiness_2021', engine, index=False, if_exists='replace')
data_2022.to_sql('happiness_2022', engine, index=False, if_exists='replace')


# First looks at the datas itself 

print(data_2022.shape)
data_2022.head(10)

print(data_2021.shape)
data_2021.head(4)
to 
print(data_2015.shape)
data_2015.head(4)

data_2015.shape, data_2016.shape, data_2017.shape, data_2019.shape, data_2020.shape, data_2021.shape,data_2022.shape

#Add year column
yrs = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']
dfs = [data_2015, data_2016, data_2017, data_2018, data_2019, data_2020, data_2021, data_2022]
for i in range(0,8):
    dfs[i]['Year'] = yrs[i]

#Explore common column names
data_2015.columns.to_list()
data_2016.columns.to_list()
data_2017.columns.to_list()
data_2018.columns.to_list()
data_2019.columns.to_list()
data_2020.columns.to_list()
data_2021.columns.to_list()
data_2022.columns.to_list()

# 2015
data_2015 = data_2015.rename(columns={'Family':'Family (Social Support)'})

data_2015.head(2)

# 2016
data_2016 = data_2016.rename(columns={'Family':'Family (Social Support)'})

#2017
data_2017.columns.to_list()
data_2017 = data_2017.rename(columns={'Happiness.Rank':'Happiness Rank', 'Happiness.Score':'Happiness Score','Economy..GDP.per.Capita.':'Economy (GDP per Capita)','Family':'Family (Social Support)','Health..Life.Expectancy.':'Health (Life Expectancy)','Trust..Government.Corruption.':'Trust (Government Corruption)'})

data_2017 = data_2017.merge(data_2015[["Country","Region"]], on="Country", how="left")
data_2017["Region"] = data_2017["Region"].fillna('-')

data_2017.head(2)

# 2018 
data_2018.columns.to_list()

data_2018.head(2)

data_2018 = data_2018.rename(columns={'Overall rank':'Happiness Rank', 'Country or region':'Country', 'Score':'Happiness Score', 'GDP per capita':'Economy (GDP per Capita)','Social support':'Family (Social Support)','Healthy life expectancy':'Health (Life Expectancy)','Freedom to make life choices':'Freedom','Perceptions of corruption':'Trust (Government Corruption)'})

data_2018.head(2)

# add region column to df2018 and df019 
data_2018 = data_2018.merge(data_2015[["Country","Region"]], on="Country", how="left")
data_2018["Region"] = data_2018["Region"].fillna('-')


data_2018.tail(2)


data_2018['Region'].value_counts()

# 2019
data_2019.columns.to_list()


data_2019 = data_2019.rename(columns={'Overall rank':'Happiness Rank', 'Country or region':'Country', 'Score':'Happiness Score', 'GDP per capita':'Economy (GDP per Capita)','Social support':'Family (Social Support)','Healthy life expectancy':'Health (Life Expectancy)','Freedom to make life choices':'Freedom','Perceptions of corruption':'Trust (Government Corruption)'})

data_2019 = data_2019.merge(data_2015[["Country","Region"]], on="Country", how="left")
data_2019["Region"] = data_2019["Region"].fillna('-')

# 2020

data_2020.columns.to_list()

data_2020 = data_2020.rename(columns={'Country name':'Country','Regional indicator': 'Region','Ladder score':'Happiness Score','Explained by: Social support':'Family (Social Support)','Explained by: Healthy life expectancy':'Health (Life Expectancy)','Explained by: Freedom to make life choices':'Freedom','Explained by: Perceptions of corruption':'Trust (Government Corruption)','Explained by: Log GDP per capita':'Economy (GDP per Capita)','Explained by: Generosity':'Generosity'})


data_2020['Happiness Rank'] = [i for i in range(1, len(data_2020.index)+1)]

data_2020 = data_2020.loc[:,~data_2020.columns.duplicated(keep='last')]

data_2020.head(2)

# 2021 

data_2021.columns.to_list()

data_2021 = data_2021.rename(columns={'Country name':'Country','Regional indicator': 'Region','Ladder score':'Happiness Score','Explained by: Social support':'Family (Social Support)','Explained by: Healthy life expectancy':'Health (Life Expectancy)','Explained by: Freedom to make life choices':'Freedom','Explained by: Perceptions of corruption':'Trust (Government Corruption)','Explained by: Log GDP per capita':'Economy (GDP per Capita)','Explained by: Generosity':'Generosity'})



data_2021 = data_2021.loc[:,~data_2021.columns.duplicated(keep='last')]

data_2021['Happiness Rank'] = [i for i in range(1, len(data_2021.index)+1)]

data_2021.head(2)

# 2022 

data_2022.columns.to_list()


data_2022 = data_2022.merge(data_2015[["Country","Region"]], on="Country", how="left")
data_2022["Region"] = data_2022["Region"].fillna('-')

data_2022 = data_2022.rename(columns={'RANK':'Happiness Rank','Happiness score':'Happiness Score','Explained by: GDP per capita':'Economy (GDP per Capita)', 'Explained by: Social support':'Family (Social Support)','Explained by: Healthy life expectancy':'Health (Life Expectancy)','Explained by: Freedom to make life choices':'Freedom','Explained by: Generosity':'Generosity', 'Explained by: Perceptions of corruption':'Trust (Government Corruption)'})


# Merge DFS

data_2015.columns.to_list()
data_2016.columns.to_list()
data_2017.columns.to_list()
data_2018.columns.to_list()
data_2019.columns.to_list()
data_2020.columns.to_list()
data_2021.columns.to_list()
data_2022.columns.to_list()

# Define Common cols

# Extract columns from each DataFrame
columns_2015 = set(data_2015.columns)
columns_2016 = set(data_2016.columns)
columns_2017 = set(data_2017.columns)
columns_2018 = set(data_2018.columns)
columns_2019 = set(data_2019.columns)
columns_2020 = set(data_2020.columns)
columns_2021 = set(data_2021.columns)
columns_2022 = set(data_2022.columns)

# Find the common columns
common_cols = columns_2015.intersection(columns_2016, columns_2017, columns_2018, columns_2019, columns_2020, columns_2021, columns_2022)

# Convert the set of common columns to a list
common_cols = list(common_cols)

dfs = [data_2015[common_cols], data_2016[common_cols], data_2017[common_cols], data_2018[common_cols], data_2019[common_cols], data_2020[common_cols], data_2021[common_cols], data_2022[common_cols]]

df_merged = pd.DataFrame(columns=common_cols)

import pandas as pd

df_merged = pd.concat(dfs, ignore_index=True)

df_merged.shape

df_merged.dropna(axis='rows',inplace=True)

df_merged.shape

df = df_merged.to_csv('world-happiness-report-2015-2022-cleaned.csv')

